{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "vertical_stack = pd.concat([train_data, test_data], axis=0,sort = False)\n",
    "data = pd.DataFrame(vertical_stack)\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Functions for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domain(s):\n",
    "    print (set(list(data[s])))\n",
    "    return list(set(list(data[s])))\n",
    "    \n",
    "def countNull(s):\n",
    "    return (s,data[s].isnull().sum())\n",
    "\n",
    "def describe(s):\n",
    "    print (train_data[s].describe())\n",
    "    \n",
    "def count(s):\n",
    "    print (\"Null: \"+str(countNull(s)))\n",
    "    print (data[s].value_counts())\n",
    "    return list(data[s].value_counts())\n",
    "\n",
    "def count_train(s):\n",
    "    print (train_data[s].value_counts())\n",
    "    return list(train_data[s].value_counts())\n",
    "\n",
    "def print_hist(s):\n",
    "    print(train_data.hist(column=s,by='HasDetections'))\n",
    "\n",
    "def print_counter(s):\n",
    "    t = 'HasDetections'\n",
    "    l = domain(s)\n",
    "    d = {}\n",
    "    e = {}\n",
    "    for i in range(len(l)):\n",
    "        d[i] = l[i]\n",
    "        e[l[i]] = [0,0]\n",
    "\n",
    "    for i in list(zip(list(train_data[s]),list(train_data[t]))):\n",
    "    #     print(i)\n",
    "        e[i[0]][i[1]] += 1\n",
    "\n",
    "    print(e)\n",
    "\n",
    "def stat(s):\n",
    "    print_hist(s)\n",
    "    print_counter(s)\n",
    "    domain(s)\n",
    "\n",
    "def print2(s,t):\n",
    "    l = list(train_data[s])\n",
    "    m = list(train_data[t])\n",
    "    temp = []\n",
    "    for i in list(zip(l,m)):\n",
    "#         print(i)\n",
    "            temp.append(i)\n",
    "    print(list(set(temp)))\n",
    "\n",
    "def sampler(s):\n",
    "    d = dict(train_data[s].value_counts())\n",
    "    sum1 = sum(d.values())\n",
    "    m = d.keys()\n",
    "    prob = [d[x]/float(sum1) for x in d.keys()]\n",
    "    print(prob)\n",
    "    return [d.keys(),prob]\n",
    "\n",
    "def sample(composite):\n",
    "    key = list(composite[0])\n",
    "    prob = composite[1]\n",
    "    a = random.random()\n",
    "    sofar = 0\n",
    "    for i in range(len(key)):\n",
    "        sofar += prob[i]\n",
    "        if(a <= sofar):\n",
    "            return key[i]\n",
    "    return key[len(key)-1]\n",
    "\n",
    "def replace_null(s):\n",
    "    composite = sampler(s)\n",
    "    l = list(train_data[s])\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        if(pd.isna(l[i])):\n",
    "            l[i] = sample(composite)\n",
    "    \n",
    "    train_data[s] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous exploration - Each cell represents a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null: ('ProductName', 0)\n",
      "win8defender    10311\n",
      "mse               113\n",
      "Name: ProductName, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10311, 113]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count('ProductName')\n",
    "#OHT because of 2 distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count('CountryIdentifier')\n",
    "# count('CityIdentifier')\n",
    "# count('GeoNameIdentifier')\n",
    "\n",
    "count('OrganizationIdentifier')\n",
    "replace_null('OrganizationIdentifier')\n",
    "count('OrganizationIdentifier')\n",
    "train_data['OrganizationIdentifier']\n",
    "# print2('CityIdentifier','OrganizationIdentifier')\n",
    "# count('LocaleEnglishNameIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# domain('IsSxsPassiveMode')\n",
    "print(count('IsSxsPassiveMode'))\n",
    "plt.scatter(data['IsSxsPassiveMode'],data['HasDetections']) # 50-50\n",
    "plt.show()\n",
    "\n",
    "#Doing nothing to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# AVProductStatesIdentifier, AVProductsInstalled, AVProductsEnabled\n",
    "\n",
    "#This shows that the null values of these 3 columns coincide and hence are positively correlated\n",
    "l1 = train_data['AVProductStatesIdentifier']\n",
    "l2 = train_data['AVProductsInstalled']\n",
    "l3 = train_data['AVProductsEnabled']\n",
    "x = l1.isnull().sum()\n",
    "l1 = l1.fillna(-1)\n",
    "l2 = l2.fillna(-1)\n",
    "l3 = l3.fillna(-1)\n",
    "l = list(zip(l1,l2,l3))\n",
    "cnt = 0\n",
    "for i in l: \n",
    "#     print(i[0],i[1])\n",
    "    if(i[0]+1 == 0 and i[1]+1 == 0 and i[2]+1 == 0):\n",
    "        cnt+=1\n",
    "\n",
    "print(cnt == x)\n",
    "\n",
    "#There are 37 NULL values in AVProductStatesIdentifier\n",
    "#There are 36 NULL values in IsProtected\n",
    "#According to the meaning, it returns true or false baed on a spynet's report for AVProductStateIdentifier\n",
    "#IsProtected should be combined with the other 3 features mentioned above\n",
    "l1 = train_data['IsProtected']\n",
    "l2 = train_data['AVProductStatesIdentifier']\n",
    "\n",
    "l1 = l1.fillna(-1)\n",
    "l2 = l2.fillna(-1)\n",
    "l = list(zip(l1,l2))\n",
    "\n",
    "cnt = 0\n",
    "counter = 0\n",
    "for i in l: \n",
    "    if(i[0]+1 == 0 and i[1]+1 == 0):\n",
    "        cnt+=1\n",
    "\n",
    "print(cnt) #Outputs 36, i.e. all values which are null in IsProtected are null in the other 3 columns, with the exception of one, where the device isn't protected\n",
    "\n",
    "#Potential idea -  we'll rely on the spynet report and delete the 3 fields, while using sampler for isProtected\n",
    "\n",
    "#Potential idea - use logistic regression to learn the spynet report\n",
    "#Predict the other 3 AV fields using sampler and then use logistic regression to learn isProtected\n",
    "#Then delete the 3AV fields\n",
    "\n",
    "#Right now - just use sampler for everything and leave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(set(list(zip(list(train_data['AVProductStatesIdentifier']),list(train_data['AVProductsInstalled']),list(train_data['AVProductsEnabled']),list(train_data['IsProtected'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain('HasTpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#OsVer\n",
    "#I don't think this is going to be helpful, so don't execute this\n",
    "train_data.hist(column='OsVer',by='HasDetections')\n",
    "count_train('OsVer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OSBuild - Is there a correlation between OSVer and OsBuild? \n",
    "# print2('OsVer','OsBuild')\n",
    "count('OsVer')\n",
    "print2('OsVer','OsBuild')\n",
    "# print(max(list(train_data['OsBuild'])))\n",
    "count('OsSuite')\n",
    "print2('OsBuildLab','ProductName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# th1 - Windows 10 Threshold\n",
    "# rs1 - Windows 10 RedStone\n",
    "# To do - sort these values based on the below order and give them a Label Encoding\n",
    "# windows7 < windows8.1 < th1 < th2 < rs1 < rs2 < rs3 < rs4 < pre res5\n",
    "# domain('OsPlatformSubRelease')\n",
    "# count('OsPlatformSubRelease')\n",
    "label_update = {}\n",
    "label_update['windows7'] = 1\n",
    "label_update['windows8.1'] = 2\n",
    "label_update['th1'] = 3\n",
    "label_update['th2'] = 4\n",
    "label_update['rs1'] = 5\n",
    "label_update['rs2'] = 6\n",
    "label_update['rs3'] = 7\n",
    "label_update['rs4'] = 8\n",
    "label_update['prers5'] = 9\n",
    "train_data['OsPlatformSubRelease'] = pd.DataFrame([label_update[x] for x in list(train_data['OsPlatformSubRelease'])])\n",
    "domain('OsPlatformSubRelease')\n",
    "# stat('OsPlatformSubRelease')\n",
    "\n",
    "#Done for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain('Census_MDC2FormFactor')\n",
    "count('Census_MDC2FormFactor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SmartScreen - Doesn't work. The data is way too noisy\n",
    "print(train_data.hist(column='SmartScreen',by='AVProductsEnabled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exists not set favours 1\n",
    "l = list(train_data['SmartScreen'])\n",
    "m = list(train_data['HasDetections'])\n",
    "cnt = [0,0]\n",
    "for i in list(zip(l,m)):\n",
    "    if(pd.isna(i[0])): cnt[i[1]] += 1\n",
    "\n",
    "#How null values affects the outcome. It doesn't. So, we'll impute it using sampler\n",
    "print(cnt) #Outputs [1966,1806]\n",
    "print_counter('SmartScreen')\n",
    "count('SmartScreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# domain('Census_OEMNameIdentifier')\n",
    "# count('Census_OEMNameIdentifier')\n",
    "count('Census_OEMModelIdentifier')\n",
    "# train_data['Census_OEMNameIdentifier'].describe()\n",
    "train_data['Census_OEMModelIdentifier'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Census_ProcessorCoreCount 50-50 after removing outliers. Why?\n",
    "# The NULL values of these 3 columns coincide, so they have a heave positive correlation\n",
    "train_data['Census_ProcessorCoreCount'].fillna(4)\n",
    "# train_data.loc[train_data['Census_ProcessorCoreCount'] > 12] = 0\n",
    "count('Census_ProcessorCoreCount')\n",
    "# stat('Census_ProcessorCoreCount')\n",
    "count('Census_ProcessorManufacturerIdentifier')\n",
    "count('Census_ProcessorModelIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Census_IsAlwaysOnAlwaysConnectedCapable\n",
    "stat('Census_IsAlwaysOnAlwaysConnectedCapable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Census_IsPenCapable\n",
    "stat('Census_IsPenCapable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Census_IsTouchEnabled\n",
    "stat('Census_IsTouchEnabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Census_InternalPrimaryDiagonalDisplaySizeInInches , Census_InternalPrimaryDisplayResolutionHorizontal , Census_InternalPrimaryDisplayResolutionVertical \n",
    "\n",
    "#This shows that the null values of these 3 columns coincide and hence they are positively correlated\n",
    "l1 = train_data['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "l2 = train_data['Census_InternalPrimaryDisplayResolutionHorizontal']\n",
    "l3 = train_data['Census_InternalPrimaryDisplayResolutionVertical']\n",
    "x = l1.isnull().sum()\n",
    "l1 = l1.fillna(-1)\n",
    "l2 = l2.fillna(-1)\n",
    "l3 = l3.fillna(-1)\n",
    "l = list(zip(l1,l2,l3))\n",
    "cnt = 0\n",
    "for i in l: \n",
    "    if(i[0]+1 == 0 and i[1]+1 == 0 and i[2]+1 == 0):\n",
    "        cnt+=1\n",
    "\n",
    "print(cnt == x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Census_PrimaryDiskTotalCapacity, Census_SystemVolumeTotalCapacity\n",
    "\n",
    "#This shows that the null values of these 2 columns coincide and hence are positively correlated. The probabilty of it happening, is exponentially low\n",
    "l1 = train_data['Census_PrimaryDiskTotalCapacity']\n",
    "l2 = train_data['Census_SystemVolumeTotalCapacity']\n",
    "x = l1.isnull().sum()\n",
    "l1 = l1.fillna(-1)\n",
    "l2 = l2.fillna(-1)\n",
    "l = list(zip(l1,l2))\n",
    "cnt = 0\n",
    "for i in l: \n",
    "#     print(i[0],i[1])\n",
    "    if(i[0]+1 == 0 and i[1]+1 == 0):\n",
    "        cnt+=1\n",
    "print(cnt == x)\n",
    "\n",
    "count('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain('Census_DeviceFamily')\n",
    "count('Census_DeviceFamily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 outlier for th1_st1 > th_1, but otherwise this relations holds\n",
    "l = ['th1','th1_st1','th2_release','th2_release_sec','rs_prerelease','rs_prerelease_flt','rs1_release','rs2_release','rs3_release','rs3_release_svc_escrow','rs3_release_svc_escrow_im','rs4_release','rs5_release']\n",
    "print(len(l))\n",
    "\n",
    "# print2('Census_OSVersion','Census_OSBranch')\n",
    "# domain('Census_OSVersion')\n",
    "# domain('Census_OSArchitecture')\n",
    "# domain('Census_OSBuildNumber')\n",
    "# print2('Census_OSVersion','Census_OSBuildNumber')\n",
    "# domain('Census_OSBuildRevision')\n",
    "# print2('Census_OSVersion','Census_OSBuildRevision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stat('Census_OSEdition')\n",
    "#These might be mistakes\n",
    "# train_data.loc[train_data['Census_OSEdition'] == 'ProfessionalN'] = 'Professional'\n",
    "# train_data.loc[train_data['Census_OSEdition'] == 'EducationN'] = 'Education'\n",
    "\n",
    "# count('Census_OSEdition')\n",
    "# print_counter('Census_OSBranch')\n",
    "# print2('')\n",
    "\n",
    "# for i in {0, 'CoreCountrySpecific', 'ServerStandardEval', 'EnterpriseS', 'Professional', 'Cloud', 'CoreN', 'EducationN', 'Core', 'Enterprise', 'ProfessionalEducation', 'ServerDatacenterEval', 'ProfessionalN', 'ServerStandard', 'Education', 'CoreSingleLanguage'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain('Platform')\n",
    "domain('Processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SkuEdition - 50/50\n",
    "count('SkuEdition')\n",
    "print_counter('SkuEdition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('IeVerIdentifier')\n",
    "replace_null('IeVerIdentifier')\n",
    "count('IeVerIdentifier')\n",
    "\n",
    "#Replace null with the sampler\n",
    "#Should have some kind of encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_null('Firewall')\n",
    "count('Firewall')\n",
    "# print_counter('Firewall') \n",
    "replace_null('UacLuaenable')\n",
    "count('UacLuaenable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count('DefaultBrowsersIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 43. Census_PrimaryDiskTotalCapacity -\n",
    "# 44. Census_PrimaryDiskTypeName -\n",
    "# 45. Census_SystemVolumeTotalCapacity -\n",
    "# 46. Census_HasOpticalDiskDrive -\n",
    "# 47. Census_TotalPhysicalRAM -\n",
    "# count('Census_PrimaryDiskTotalCapacity')\n",
    "count('Census_PrimaryDiskTypeName')\n",
    "train_data['Census_PrimaryDiskTypeName'].replace('UNKNOWN',np.nan,inplace = True)\n",
    "train_data['Census_PrimaryDiskTypeName'].replace('Unspecified',np.nan,inplace = True)\n",
    "count('Census_PrimaryDiskTypeName')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print2('Census_SystemVolumeTotalCapacity','Census_PrimaryDiskTotalCapacity')\n",
    "#For imputing this, equate it to the 'Census_PrimaryDiskTotalCapacity'\n",
    "# FILL PrimaryDiskTotalCapacity First!!!\n",
    "count('Census_SystemVolumeTotalCapacity')\n",
    "replace_null('Census_PrimaryDiskTotalCapacity')\n",
    "train_data['Census_SystemVolumeTotalCapacity'].fillna(train_data['Census_PrimaryDiskTotalCapacity'],inplace = True)\n",
    "count('Census_SystemVolumeTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_HasOpticalDiskDrive')\n",
    "# 46. Census_HasOpticalDiskDrive -\n",
    "# 47. Census_TotalPhysicalRAM -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_ChassisTypeName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_PowerPlatformRoleName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Census_InternalBatteryType - \n",
    "# 54. Census_InternalBatteryNumberOfCharges -\n",
    "count('Census_InternalBatteryType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count('Census_InternalBatteryNumberOfCharges')\n",
    "train_data['Census_InternalBatteryNumberOfCharges'].fillna(train_data['Census_InternalBatteryNumberOfCharges'].mode()[0],inplace = True)\n",
    "stat('Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_OSEdition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_OSSkuName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_OSInstallTypeName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_OSInstallLanguageIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_OSUILocaleIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count('Census_OSWUAutoUpdateOptionsName')\n",
    "train_data['Census_OSWUAutoUpdateOptionsName'].replace('UNKNOWN',np.nan,inplace = True)\n",
    "replace_null('Census_OSWUAutoUpdateOptionsName')\n",
    "count('Census_OSWUAutoUpdateOptionsName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null: ('Census_IsPortableOperatingSystem', 0)\n",
      "0    15510\n",
      "1       14\n",
      "Name: Census_IsPortableOperatingSystem, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15510, 14]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count('Census_IsPortableOperatingSystem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_GenuineStateName')\n",
    "\n",
    "def GenuineStateName_update(): \n",
    "    train_data['Census_GenuineStateName'].replace(['UNKNOWN'],np.nan,inplace = True)\n",
    "    composite = sampler('Census_GenuineStateName')\n",
    "    train_data['Census_GenuineStateName'].fillna(sample(composite),inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count('Census_ActivationChannel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_FlightRing')\n",
    "def CensusFlightRing_Update():\n",
    "    train_data['Census_FlightRing'].replace(['Unknown'],np.nan,inplace = True)\n",
    "    composite = sampler('Census_FlightRing')\n",
    "    train_data['Census_FlightRing'].fillna(sample(composite),inplace = True)\n",
    "\n",
    "# CensusFlightRing_Update()\n",
    "# count('Census_FlightRing')\n",
    "count('Census_IsFlightingInternal')\n",
    "count('Census_IsFlightsDisabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_ThresholdOptIn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_FirmwareManufacturerIdentifier')\n",
    "count('Census_FirmwareVersionIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Census_IsSecureBootEnabled')\n",
    "count('Census_IsWIMBootEnabled')\n",
    "count('Census_IsVirtualDevice')\n",
    "count('Census_IsTouchEnabled')\n",
    "count('Census_IsPenCapable')\n",
    "count('Census_IsAlwaysOnAlwaysConnectedCapable')\n",
    "count('Census_IsAlwaysOnAlwaysConnectedCapable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 True\n"
     ]
    }
   ],
   "source": [
    "# Wdft_IsGamer and Wdft_RegionIdentifier are related\n",
    "\n",
    "#This shows that the null values of these 2 columns coincide and hence are positively correlated\n",
    "l1 = train_data['Wdft_IsGamer']\n",
    "l2 = train_data['Wdft_RegionIdentifier']\n",
    "x = l1.isnull().sum()\n",
    "l1 = l1.fillna(-1)\n",
    "l2 = l2.fillna(-1)\n",
    "l = list(zip(l1,l2))\n",
    "cnt = 0\n",
    "for i in l: \n",
    "#     print(i[0],i[1])\n",
    "    if(i[0]+1 == 0 and i[1]+1 == 0):\n",
    "        cnt+=1\n",
    "print(cnt,cnt == x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count('Wdft_IsGamer')\n",
    "count('Wdft_RegionIdentifier')\n",
    "\n",
    "def WdftGamer_Update():\n",
    "#     composite = sampler('Wdft_IsGamer')\n",
    "#     train_data['Wdft_IsGamer'].fillna(sample(composite),inplace = True)\n",
    "    \n",
    "#     composite = sampler('Wdft_RegionIdentifier')\n",
    "#     train_data['Wdft_RegionIdentifier'].fillna(method = 'sample(composite)',inplace = True)\n",
    "#     train_data['Wdft_RegionIdentifier'] = train_data['Wdft_RegionIdentifier'].apply(lambda x : sample(composite))\n",
    "    replace_sample('Wdft_RegionIdentifier')\n",
    "    replace_sample('')\n",
    "\n",
    "WdftGamer_Update()\n",
    "count('Wdft_IsGamer')\n",
    "count('Wdft_RegionIdentifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Wdft_IsGamer'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
